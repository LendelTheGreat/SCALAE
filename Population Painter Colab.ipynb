{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/LendelTheGreat/SCALAE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --id 1pqjjx8zRSPsTzPXVQiFf3PgmGnJpLSQn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from IPython.display import HTML, Image, clear_output\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode, b64encode\n",
    "import PIL\n",
    "import PIL.ImageOps\n",
    "import io\n",
    "\n",
    "SCALAE_PATH = os.path.join(os.path.expanduser('~'), 'stylegan2-pytorch')\n",
    "if SCALAE_PATH not in sys.path:\n",
    "    sys.path.append(SCALAE_PATH)\n",
    "from checkpointer import Checkpointer\n",
    "from defaults import get_cfg_defaults\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading config...')\n",
    "config_file='configs/popgan.yaml'\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(config_file)\n",
    "cfg.freeze()\n",
    "\n",
    "print('Initializing model...')\n",
    "torch.cuda.set_device(0)\n",
    "layer_count = cfg.MODEL.LAYER_COUNT\n",
    "model = Model(\n",
    "    startf=cfg.MODEL.START_CHANNEL_COUNT,\n",
    "    layer_count=cfg.MODEL.LAYER_COUNT,\n",
    "    maxf=cfg.MODEL.MAX_CHANNEL_COUNT,\n",
    "    latent_size=cfg.MODEL.LATENT_SPACE_SIZE,\n",
    "    truncation_psi=cfg.MODEL.TRUNCATIOM_PSI,\n",
    "    truncation_cutoff=cfg.MODEL.TRUNCATIOM_CUTOFF,\n",
    "    mapping_layers=cfg.MODEL.MAPPING_LAYERS,\n",
    "    channels=cfg.MODEL.CHANNELS,\n",
    "    generator=cfg.MODEL.GENERATOR,\n",
    "    encoder=cfg.MODEL.ENCODER)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "model.requires_grad_(False)\n",
    "\n",
    "print('Loading checkpoint...')\n",
    "model_dict = {\n",
    "    'discriminator_s': model.encoder,\n",
    "    'generator_s': model.decoder,\n",
    "    'mapping_tl_s': model.mapping_tl,\n",
    "    'mapping_fl_s': model.mapping_fl,\n",
    "    'dlatent_avg': model.dlatent_avg\n",
    "}\n",
    "checkpointer = Checkpointer(cfg, model_dict)\n",
    "extra_checkpoint_data = checkpointer.load(file_name='/content/scalae_pop2sat_1024_e200.pth')\n",
    "\n",
    "print('READY!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(seed):\n",
    "    with torch.no_grad():\n",
    "        rng = np.random.RandomState(seed)\n",
    "        z = rng.standard_normal(cfg.MODEL.LATENT_SPACE_SIZE)\n",
    "        z = torch.from_numpy(z).float().cuda().unsqueeze(0)\n",
    "    return z\n",
    "\n",
    "def z2w(z):\n",
    "    with torch.no_grad():\n",
    "        w = model.mapping_fl(z)\n",
    "    return w\n",
    "\n",
    "def sample_noise(seed):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    noise = [0] + [torch.from_numpy(rng.standard_normal((1, 1, 2 ** i, 2 ** i))) for i in range(1, 11)]\n",
    "    return noise\n",
    "\n",
    "def decode(w, pop, noise):\n",
    "    return torch.clamp(model.decoder(w, pop, layer_count - 1, 1, noise=noise), -1., 1.)\n",
    "\n",
    "def numpy_to_tensor(img):\n",
    "    if len(img.shape) < 3:\n",
    "        img = np.expand_dims(img, 2)\n",
    "    img = img.transpose((2, 0, 1))\n",
    "    x = torch.tensor(np.asarray(img, dtype=np.float32), requires_grad=False).cuda() / 0.5 - 1.\n",
    "    return x\n",
    "\n",
    "def tensor_to_numpy(img):\n",
    "    img = img * 0.5 + 0.5\n",
    "    img = img.cpu().squeeze().numpy()\n",
    "    if len(img.shape) == 3:\n",
    "        img = np.moveaxis(img, 0, 2)\n",
    "    return img\n",
    "\n",
    "def generate(w, np_pop, noise):\n",
    "    pop = numpy_to_tensor(np_pop).unsqueeze(0)\n",
    "    img = torch.clamp(model.decoder(w, pop, layer_count - 1, 1, noise=noise), -1., 1.)\n",
    "    img = tensor_to_numpy(img)\n",
    "    return img\n",
    "\n",
    "def numpy_to_PIL(img, img_size=256):\n",
    "    img = np.clip(img, 0, 1)\n",
    "    img = (img *255).astype(np.uint8)\n",
    "    img = PIL.Image.fromarray(img)\n",
    "    img = img.resize((img_size, img_size))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas_html = \"\"\"\n",
    "<canvas width=%d height=%d></canvas>\n",
    "<button>Generate Fake Satellite Image</button>\n",
    "<script>\n",
    "var canvas = document.querySelector('canvas')\n",
    "var ctx = canvas.getContext('2d')\n",
    "ctx.lineWidth = %d\n",
    "ctx.strokeStyle = '#ffffff';\n",
    "base_image = new Image();\n",
    "base_image.src = 'data:image/png;base64,%s';\n",
    "base_image.onload = function(){\n",
    "  ctx.drawImage(base_image, 0, 0);\n",
    "}\n",
    "var button = document.querySelector('button')\n",
    "var mouse = {x: 0, y: 0}\n",
    "canvas.addEventListener('mousemove', function(e) {\n",
    "  mouse.x = e.pageX - this.offsetLeft\n",
    "  mouse.y = e.pageY - this.offsetTop\n",
    "})\n",
    "canvas.onmousedown = ()=>{\n",
    "  ctx.beginPath()\n",
    "  ctx.moveTo(mouse.x, mouse.y)\n",
    "  canvas.addEventListener('mousemove', onPaint)\n",
    "}\n",
    "canvas.onmouseup = ()=>{\n",
    "  canvas.removeEventListener('mousemove', onPaint)\n",
    "}\n",
    "var onPaint = ()=>{\n",
    "  ctx.lineTo(mouse.x, mouse.y)\n",
    "  ctx.stroke()\n",
    "}\n",
    "var data = new Promise(resolve=>{\n",
    "  button.onclick = ()=>{\n",
    "    resolve(canvas.toDataURL('image/png'))\n",
    "  }\n",
    "})\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "def imgfile_to_string(file):\n",
    "    an_image = PIL.Image.open(file)\n",
    "    output = io.BytesIO()\n",
    "    an_image.save(output, format=\"png\")\n",
    "    image_as_string = output.getvalue()\n",
    "    return image_as_string\n",
    "\n",
    "def run(img_size=256, seed=0):\n",
    "    line_width = 1\n",
    "\n",
    "    pop = np.zeros((img_size, img_size))\n",
    "    numpy_to_PIL(pop, img_size).save(\"pop.png\")\n",
    "\n",
    "    z = sample_z(seed)\n",
    "    w = z2w(z)\n",
    "    noise = sample_noise(seed)\n",
    "\n",
    "    img = generate(w, pop, noise)\n",
    "    img = numpy_to_PIL(img, img_size)\n",
    "    img.save(\"img.png\")\n",
    "\n",
    "    while True:\n",
    "        clear_output()\n",
    "        pop_str = b64encode(imgfile_to_string('pop.png')).decode(\"utf-8\")\n",
    "        display(HTML(canvas_html % (img_size, img_size, line_width, pop_str)))\n",
    "        display(Image('img.png'))\n",
    "\n",
    "        data = eval_js(\"data\").split(',')[1]\n",
    "\n",
    "        binary = b64decode(data)\n",
    "        with open(\"pop.png\", 'wb') as f:\n",
    "            f.write(binary)\n",
    "\n",
    "        pop = PIL.Image.open(\"pop.png\")\n",
    "        pop = np.array(pop) / 255\n",
    "        pop = pop[:, :, 0]\n",
    "\n",
    "        img = generate(w, pop, noise_seed)\n",
    "        img = numpy_to_PIL(img, img_size)\n",
    "        img.save(\"img.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "py37_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
